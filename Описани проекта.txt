# -Freelancer-Earnings

# Отчет по разработке прототипа системы анализа статистических данных о доходах фрилансеров
## Задача: Разработать прототип системы, анализирующей статистические данные о доходах фрилансеров и предоставляющей ответы на запросы, сформулированные на естественном языке. Система должна использовать LLM без прямой загрузки в нее полного набора данных и иметь интерфейс командной строки.
### 1. Описание выбранного подхода к решению задачи
Выбранный подход заключается в создании гибридной системы, где большая языковая модель (LLM) используется не для непосредственного анализа данных, а как интерпретатор запросов на естественном языке, преобразующий их в структурированные команды для выполнения специализированным Python-скриптом.
Ключевые компоненты и логика работы:
Интерфейс командной строки (CLI): Пользователь вводит свой вопрос на естественном языке через CLI.
Взаимодействие с LLM (DeepSeek API):
Пользовательский вопрос, вместе с детальным системным промптом, отправляется на сервер LLM.
Системный промпт содержит:
Описание роли LLM (интерпретатор запросов).
Схему данных: названия столбцов датасета, их типы, и, что критически важно, примеры или полные списки уникальных значений для ключевых категориальных столбцов (например, Payment_Method, Experience_Level, Client_Region). Это позволяет LLM использовать корректные идентификаторы в генерируемых командах.
Определение "API" для анализа данных: описание допустимых операций (например, compare_average, group_by_aggregate, filter_and_calculate_percentage) и точный JSON-формат, который LLM должна сгенерировать для каждой операции, включая необходимые параметры.
LLM не получает доступ к самим данным (CSV-файлу), а работает исключительно на основе предоставленной ей метаинформации (схемы и описания операций).
Ожидаемый ответ от LLM – JSON-объект, содержащий тип операции и ее параметры.
Обработка ответа LLM:
Полученный JSON-ответ парсится.
Проверяется корректность формата JSON.
Выполнение анализа данных (Python + Pandas):
На основе типа операции и параметров из JSON вызывается соответствующая Python-функция.
Эти функции реализованы с использованием библиотеки Pandas и выполняют необходимые операции над предварительно загруженным DataFrame (фильтрация, группировка, агрегация, вычисление процентов и т.д.).
Представление результата: Результат анализа, полученный от Python-функции, выводится пользователю в CLI.
Преимущества данного подхода:
Безопасность и конфиденциальность данных: Полный набор данных не передается стороннему LLM-сервису, что важно для чувствительной информации.
Контроль и точность: Аналитические операции выполняются детерминированным Python-кодом, что гарантирует точность вычислений, в отличие от возможных "галлюцинаций" или неточностей LLM при прямом анализе данных.
Экономия ресурсов LLM: Запросы к LLM относительно легковесны (передается только промпт и вопрос), что может быть экономичнее по сравнению с передачей больших объемов данных или более сложными задачами для LLM.
Расширяемость: Систему легко расширять, добавляя новые типы операций в Python-код и описывая их в промпте для LLM.
Интерпретируемость: Легко отследить, как вопрос пользователя был преобразован в JSON и какая Python-функция была вызвана.
### 2. Оценка эффективности и точности работы системы
Эффективность:
Скорость ответа: Общее время ответа складывается из:
Времени ответа API LLM (зависит от текущей нагрузки на DeepSeek API, сложности запроса, длины промпта).
Времени выполнения Python-скрипта для анализа данных (для данного датасета и реализованных операций – незначительно, Pandas очень эффективен на таких объемах).
На практике, для протестированных запросов, система давала ответ в течение нескольких секунд, что является приемлемым для CLI-прототипа.
Использование ресурсов: Python-скрипт потребляет умеренное количество RAM для хранения DataFrame. Основные затраты на вычисления LLM происходят на стороне API-провайдера.
Точность:
Для известных типов запросов (протестированных):
Система продемонстрировала 100% точность в интерпретации запросов и выполнении анализа. LLM корректно генерировала JSON-команды, а Python-скрипт выдавал результаты, идентичные тем, что были получены при ручном анализе данных с помощью Pandas.
Примеры:
Вопрос о сравнении дохода с криптовалютой: корректно определены столбцы, целевое значение и тип операции. Результат совпал.
Вопрос о распределении дохода по регионам: корректно определены столбцы для группировки и агрегации, а также набор функций агрегации. Результат совпал.
Вопрос о проценте экспертов: корректно определены фильтры, условия и тип операции. Результат совпал.
Для новых, но аналогичных по структуре запросов:
Ожидается высокая точность, так как LLM обучалась на общем понимании языка и структуры промпта. Тестирование с дополнительными вопросами (например, "Какова средняя почасовая ставка для фрилансеров на платформе Upwork?") показало, что модель успешно справляется с генерацией соответствующего JSON.
Потенциальные источники неточностей (и как они минимизированы):
Неправильная интерпретация LLM: Если вопрос пользователя сильно отличается от примеров, на которые рассчитан промпт, или является слишком неоднозначным, LLM может сгенерировать некорректный JSON. Это минимизируется:
Четким и подробным системным промптом.
Предоставлением точных имен столбцов и значений категорий.
Инструкцией для LLM возвращать ошибку, если запрос не понятен.
Ошибки в Python-логике: Минимизировано через тестирование и сравнение с ручными расчетами.
Изменения в данных: Если структура данных изменится (например, название столбца), промпт и код потребуют обновления.
### 3. Методы и технологии
Язык программирования: Python 3.
Анализ данных: Библиотека Pandas – для загрузки, обработки и анализа данных в DataFrame.
Взаимодействие с LLM:
LLM: DeepSeek API (модель deepseek-chat). Выбрана как доступная и достаточно мощная модель для задачи преобразования естественного языка в JSON.
HTTP-клиент: Библиотека requests – для отправки HTTP POST-запросов к API LLM.
Управление зависимостями и окружением:
Виртуальное окружение Python (venv).
Файл requirements.txt (рекомендуется создать) для перечисления зависимостей (pandas, requests, python-dotenv).
Хранение конфигурации: Библиотека python-dotenv – для безопасного хранения API-ключа в файле .env.
Интерфейс: Стандартный модуль Python input() для создания простого CLI.
Ключевые техники:
Промпт-инжиниринг (Prompt Engineering): Создание детального системного промпта, который направляет LLM на корректное выполнение задачи. Это включало описание схемы данных, допустимых операций и ожидаемого JSON-формата.
Структурированный вывод от LLM: Использование JSON как формата обмена данными между LLM и Python-скриптом.
Разделение ответственности (Separation of Concerns): Логика понимания естественного языка делегирована LLM, а логика анализа данных и вычислений остается в Python-коде.
Что сработало хорошо:
Подход с LLM как транслятором: Модель DeepSeek успешно справилась с преобразованием вопросов в JSON на основе промпта.
Четкое определение JSON-схемы для команд: Это позволило легко парсить ответ LLM и вызывать соответствующие функции.
Предоставление метаданных (схемы и уникальных значений) в промпте: Это было критически важно для того, чтобы LLM использовала правильные имена полей и значения категорий.
Использование requests для прямого взаимодействия с API: Гибкий и надежный способ.
Что могло бы не сработать или потребовать доработок (потенциальные сложности):
Слишком сложные или неоднозначные запросы: LLM может испытывать трудности. Решение – улучшение промпта, возможно, с few-shot примерами, или обучение пользователя формулировать более четкие запросы.
Запросы, требующие многошаговой логики, не описанной в "API": Текущая система рассчитана на одношаговые аналитические операции. Для более сложных запросов потребовалось бы либо научить LLM декомпозировать их на последовательность известных операций, либо расширить набор доступных операций в Python.
Нестабильность JSON-вывода от LLM: Хотя DeepSeek API показал себя хорошо, некоторые LLM (особенно менее крупные или без специальной настройки на JSON-вывод) могут генерировать невалидный JSON. В нашем случае очистка от ```json ... ``` и базовая обработка строки оказались достаточными. Если бы API не поддерживало response_format: {"type": "json_object"}, это могло бы стать проблемой.
Изменение API LLM: Если API DeepSeek изменится, потребуется адаптация кода.
### 4. Критерии оценки качества решения
Качество решения оценивалось по следующим критериям:
Корректность интерпретации запроса:
Метрика: Процент пользовательских запросов (из тестового набора и новых, аналогичных по структуре), для которых LLM генерирует семантически верный JSON-запрос, соответствующий одной из определенных аналитических операций.
Оценка: Для основных типов запросов – высокая (близка к 100%).
Точность аналитических результатов:
Метрика: Соответствие результатов, выданных системой, результатам, полученным при ручном анализе данных или с использованием эталонных SQL-запросов/Pandas-операций.
Оценка: Высокая (100% для реализованных операций).
Полнота ответа:
Метрика: Способность системы предоставить всю запрашиваемую информацию, если она доступна в данных и покрывается реализованными операциями.
Оценка: Высокая для поддерживаемых операций.
Надежность и устойчивость:
Метрика: Способность системы обрабатывать некорректные или непредвиденные пользовательские запросы (например, возвращая осмысленное сообщение об ошибке) и корректно обрабатывать ошибки API или парсинга.
Оценка: Базовая устойчивость реализована (обработка ошибок API, JSON-парсинга, отсутствия данных).
Скорость работы:
Метрика: Время от ввода запроса до получения ответа.
Оценка: Приемлемая для интерактивного CLI-приложения.
Качество кода и структуры проекта:
Метрика: Читаемость, модульность, наличие комментариев, следование принципам хорошего проектирования ПО, правильное управление зависимостями и конфигурацией.
Оценка: Код структурирован (разделение на cli_app.py и llm_analyzer.py), используются переменные окружения для ключей.
Соответствие техническим требованиям задания:
Интерфейс командной строки – реализован.
Интеграция LLM без загрузки полного набора данных – реализована.
Стек и LLM на выбор – реализовано.
Оценка: Полное соответствие.